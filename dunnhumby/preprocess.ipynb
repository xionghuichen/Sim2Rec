{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ffc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import sys\n",
    "from src.utils import create_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37c65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = Path.cwd()\n",
    "with open(os.path.join(proj_path, 'catalog.yml'), \"r\") as f:\n",
    "    catalog = yaml.safe_load(f)['breakfast']\n",
    "    \n",
    "with open(os.path.join(proj_path, 'params.yml'), \"r\") as f:\n",
    "    params = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d63922c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_fname = os.path.join(proj_path, catalog['xlsx_fname'])\n",
    "transactions = pd.read_excel(main_fname, skiprows=1, usecols=np.arange(12), sheet_name=catalog['sheet_names']['transactions'])\n",
    "product_lookup = pd.read_excel(main_fname, skiprows=1, usecols=np.arange(6), sheet_name=catalog['sheet_names']['products'])\n",
    "store_lookup = pd.read_excel(main_fname, skiprows=1, usecols=np.arange(9), sheet_name=catalog['sheet_names']['store'])\n",
    "store_lookup.drop(index=[22, 39], inplace=True)\n",
    "store_lookup.reset_index(drop=True, inplace=True)\n",
    "glossary = pd.read_excel(main_fname, skiprows=3, usecols=np.arange(3), sheet_name=catalog['sheet_names']['glossary'], names=['VARIABLE NAME', 'TABLE', 'DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e898c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(os.path.join(proj_path, catalog['output_dir']['dir']))\n",
    "transactions.to_csv(os.path.join(proj_path, catalog['output_dir']['dir'], catalog['output_dir']['transactions']))\n",
    "product_lookup.to_csv(os.path.join(proj_path, catalog['output_dir']['dir'], catalog['output_dir']['products']))\n",
    "store_lookup.to_csv(os.path.join(proj_path, catalog['output_dir']['dir'], catalog['output_dir']['store']))\n",
    "glossary.to_csv(os.path.join(proj_path, catalog['output_dir']['dir'], catalog['output_dir']['glossary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd06abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = transactions.merge(product_lookup, on='UPC', how='left').merge(store_lookup, left_on='STORE_NUM', right_on='STORE_ID', how='left')\n",
    "merged_data = merged_data.to_csv(os.path.join(proj_path, catalog['output_dir']['dir'], catalog['output_dir']['merged']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d81ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import make_dates\n",
    "from datetime import timedelta\n",
    "merged_data = pd.read_csv('data/processed/merged_data.csv')\n",
    "merged_data['WEEK_END_DATE'] = pd.to_datetime(merged_data['WEEK_END_DATE'])\n",
    "original_data = merged_data.copy()\n",
    "merged_data['WEEK_END_DATE'] = merged_data['WEEK_END_DATE'] + timedelta(days=3)\n",
    "data_ranges = make_dates(params['breakfast']['experiment_dates'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f75f6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_start  train_end valid_start  valid_end test_start   test_end\n",
      "0   2009-01-17 2010-12-04  2010-12-11 2011-01-01 2011-01-08 2011-01-29\n",
      "1   2009-02-14 2011-01-01  2011-01-08 2011-01-29 2011-02-05 2011-02-26\n",
      "2   2009-03-14 2011-01-29  2011-02-05 2011-02-26 2011-03-05 2011-03-26\n",
      "3   2009-04-11 2011-02-26  2011-03-05 2011-03-26 2011-04-02 2011-04-23\n",
      "4   2009-05-09 2011-03-26  2011-04-02 2011-04-23 2011-04-30 2011-05-21\n",
      "5   2009-06-06 2011-04-23  2011-04-30 2011-05-21 2011-05-28 2011-06-18\n",
      "6   2009-07-04 2011-05-21  2011-05-28 2011-06-18 2011-06-25 2011-07-16\n",
      "7   2009-08-01 2011-06-18  2011-06-25 2011-07-16 2011-07-23 2011-08-13\n",
      "8   2009-08-29 2011-07-16  2011-07-23 2011-08-13 2011-08-20 2011-09-10\n",
      "9   2009-09-26 2011-08-13  2011-08-20 2011-09-10 2011-09-17 2011-10-08\n",
      "10  2009-10-24 2011-09-10  2011-09-17 2011-10-08 2011-10-15 2011-11-05\n",
      "11  2009-11-21 2011-10-08  2011-10-15 2011-11-05 2011-11-12 2011-12-03\n",
      "12  2009-12-19 2011-11-05  2011-11-12 2011-12-03 2011-12-10 2011-12-31\n",
      "2012-01-07 00:00:00\n",
      "2009-01-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data_ranges)\n",
    "print(merged_data['WEEK_END_DATE'].max())\n",
    "print(merged_data['WEEK_END_DATE'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cd5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, plotting, space_eval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5240a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Search\n",
    "space = {\n",
    "    'eta': hp.quniform('eta', 0.02, 0.5, 0.01),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2, 10, dtype=int)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 3, 1),\n",
    "    'subsample': hp.quniform('subsample', 0.2, 1, 0.1),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.2, 1, 0.1),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(5, 150, dtype=int))\n",
    "}\n",
    "\n",
    "def optimize():\n",
    "    \n",
    "    best = fmin(_score, space, algo=tpe.suggest, trials=trials, max_evals=100, verbose=0)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb5061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
